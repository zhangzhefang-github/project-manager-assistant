# ğŸ¤– AI é¡¹ç›®ç®¡ç†åŠ©æ‰‹ | AI Project Management Assistant

<div align="center">

[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.111%2B-009688.svg)](https://fastapi.tiangolo.com/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Latest-FF6B6B.svg)](https://github.com/langchain-ai/langgraph)
[![Streamlit](https://img.shields.io/badge/Streamlit-Latest-FF4B4B.svg)](https://streamlit.io/)
[![uv](https://img.shields.io/badge/managed%20with-uv-ef5552.svg)](https://github.com/astral-sh/uv)

**ä¸€ä¸ªé€šè¿‡è¿­ä»£è‡ªæˆ‘åæ€å’Œé£é™©é™ä½ï¼Œå°†é¡¹ç›®æè¿°è½¬æ¢ä¸ºå…¨é¢ä¼˜åŒ–é¡¹ç›®è®¡åˆ’çš„æ™ºèƒ½AIä»£ç†**

[ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢
[ğŸ“– APIæ–‡æ¡£](#-apiæ–‡æ¡£) â€¢
[ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ](#-æ¶æ„æ¦‚è§ˆ) â€¢
[ğŸ¯ æ¼”ç¤º](#-æ¼”ç¤º) â€¢
[ğŸ¤ å‚ä¸è´¡çŒ®](#-å‚ä¸è´¡çŒ®) â€¢
[ğŸŒ English Version](#-overview)

</div>

---

## ğŸ“‹ ç›®å½• | Table of Contents

**ä¸­æ–‡ç‰ˆæœ¬ | Chinese Version:**
- [é¡¹ç›®æ¦‚è¿°](#-é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [æŠ€æœ¯äº®ç‚¹](#-æŠ€æœ¯äº®ç‚¹)
- [æ¶æ„æ¦‚è§ˆ](#-æ¶æ„æ¦‚è§ˆ)
- [æŠ€æœ¯æ ˆ](#-æŠ€æœ¯æ ˆ)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [å®‰è£…éƒ¨ç½²](#-å®‰è£…éƒ¨ç½²)
- [ä½¿ç”¨æŒ‡å—](#-ä½¿ç”¨æŒ‡å—)
- [APIæ–‡æ¡£](#-apiæ–‡æ¡£)
- [æ¼”ç¤º](#-æ¼”ç¤º)
- [é…ç½®è¯´æ˜](#-é…ç½®è¯´æ˜)
- [æ•…éšœæ’æŸ¥](#-æ•…éšœæ’æŸ¥)
- [å‚ä¸è´¡çŒ®](#-å‚ä¸è´¡çŒ®)
- [è®¸å¯è¯](#-è®¸å¯è¯)

**English Version:**
- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture Overview](#-architecture-overview)
- [Technology Stack](#-technology-stack)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Demo](#-demo)
- [Configuration](#-configuration)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

# ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ–‡æ¡£ | Chinese Documentation

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

**AIé¡¹ç›®ç®¡ç†åŠ©æ‰‹**æ˜¯ä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„æ™ºèƒ½ä»£ç†ï¼Œé€šè¿‡è‡ªåŠ¨å°†è‡ªç„¶è¯­è¨€é¡¹ç›®æè¿°è½¬æ¢ä¸ºå…¨é¢çš„ç»“æ„åŒ–é¡¹ç›®è®¡åˆ’ï¼Œå½»åº•é©æ–°é¡¹ç›®è§„åˆ’æ–¹å¼ã€‚

### é¡¹ç›®ç‰¹è‰²

ğŸ§  **è‡ªæˆ‘ä¼˜åŒ–AI**ï¼šä½¿ç”¨è¿­ä»£è‡ªæˆ‘åæ€æŒç»­æ”¹è¿›é¡¹ç›®è®¡åˆ’  
âš¡ **å®æ—¶è¿›åº¦è¿½è¸ª**ï¼šAIä»£ç†æ‰§è¡Œçš„å®æ—¶å¯è§†åŒ–ï¼Œè¯¦ç»†èŠ‚ç‚¹çŠ¶æ€å±•ç¤º  
ğŸ”„ **è‡ªé€‚åº”æ¶æ„**ï¼šæ¨¡å‹é€‚é…å™¨æ¨¡å¼ç¡®ä¿æ— ç¼æ•°æ®è½¬æ¢  
ğŸŒŠ **æµå¼æ›´æ–°**ï¼šServer-Sent Eventsæä¾›å®æ—¶ç”¨æˆ·ä½“éªŒ  
ğŸ“Š **é£é™©é©±åŠ¨ä¼˜åŒ–**ï¼šé€šè¿‡æ™ºèƒ½è¿­ä»£è‡ªåŠ¨é™ä½é¡¹ç›®é£é™©  
ğŸŒ **ä¸­è‹±åŒè¯­**ï¼šåŸç”Ÿæ”¯æŒä¸­è‹±æ–‡ç•Œé¢å’ŒAIè¾“å‡º  

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸª **æ ¸å¿ƒAIèƒ½åŠ›**
- **ğŸ§  æ™ºèƒ½ä»»åŠ¡æå–**ï¼šé€šè¿‡æ™ºèƒ½ä¸Šä¸‹æ–‡ç†è§£å°†é¡¹ç›®æè¿°è½¬æ¢ä¸ºå¯æ‰§è¡Œä»»åŠ¡
- **ğŸ”— ä¾èµ–å…³ç³»åˆ†æ**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œæ˜ å°„å¤æ‚çš„ä»»åŠ¡å…³ç³»
- **ğŸ“… ä¼˜åŒ–è°ƒåº¦**ï¼šè€ƒè™‘èµ„æºçº¦æŸåˆ›å»ºé«˜æ•ˆæ—¶é—´çº¿
- **ğŸ‘¥ æ™ºèƒ½å›¢é˜Ÿåˆ†é…**ï¼šåŸºäºæŠ€èƒ½å’Œå¯ç”¨æ€§å°†ä»»åŠ¡åŒ¹é…ç»™å›¢é˜Ÿæˆå‘˜
- **âš ï¸ é£é™©è¯„ä¼°**ï¼šä¸»åŠ¨è¯†åˆ«å’Œç¼“è§£é¡¹ç›®é£é™©
- **âœ¨ æ´å¯Ÿç”Ÿæˆ**ï¼šAIé©±åŠ¨çš„é¡¹ç›®æ”¹è¿›å»ºè®®

### ğŸ› ï¸ **æŠ€æœ¯å“è¶Šæ€§**
- **ğŸ”„ è¿­ä»£è‡ªæˆ‘åæ€**ï¼šä»£ç†é€šè¿‡å¤šè½®ä¼˜åŒ–æŒç»­æ”¹è¿›è®¡åˆ’
- **ğŸ“Š å®æ—¶è¿›åº¦å¯è§†åŒ–**ï¼š6é˜¶æ®µAIå·¥ä½œæµæ‰§è¡Œçš„å®æ—¶è·Ÿè¸ª
- **âš¡ å¼‚æ­¥å¤„ç†**ï¼šRedisé˜Ÿåˆ—çš„éé˜»å¡ä»»åŠ¡æ‰§è¡Œ
- **ğŸŒŠ Server-Sent Events**ï¼šå‰ç«¯å®æ—¶æµå¼æ›´æ–°
- **ğŸ›¡ï¸ ä¼˜é›…é™çº§**ï¼šå¸¦æœ‰å›é€€æœºåˆ¶çš„å¥å£®é”™è¯¯å¤„ç†
- **ğŸ¯ ç±»å‹å®‰å…¨**ï¼šå®Œæ•´çš„PydanticéªŒè¯ç¡®ä¿æ•°æ®å®Œæ•´æ€§

### ğŸ¨ **ç”¨æˆ·ä½“éªŒ**
- **ğŸ“± äº¤äº’å¼Webç•Œé¢**ï¼šåŸºäºStreamlitçš„ç¾è§‚UIï¼Œå…·æœ‰å®æ—¶æ›´æ–°
- **ğŸŒ å¤šè¯­è¨€æ”¯æŒ**ï¼šä¸­æ–‡å’Œè‹±æ–‡ç•Œé¢
- **ğŸ“ˆ è¿›åº¦å¯è§†åŒ–**ï¼šè¯¦ç»†çš„å·¥ä½œæµè¿›åº¦ï¼ŒèŠ‚ç‚¹çº§çŠ¶æ€æ˜¾ç¤º
- **ğŸ” æ‰‹åŠ¨çŠ¶æ€æ£€æŸ¥**ï¼šæŒ‰éœ€ç»“æœéªŒè¯å’ŒçŠ¶æ€æŸ¥è¯¢
- **ğŸ“Š ä¸°å¯Œç»“æœå±•ç¤º**ï¼šåŒ…å«ä»»åŠ¡ã€æ—¥ç¨‹å’Œé£é™©è¯„ä¼°çš„å…¨é¢é¡¹ç›®è®¡åˆ’

## ğŸ’¡ æŠ€æœ¯äº®ç‚¹

### ğŸ—ï¸ **æŠ€æœ¯æ¶æ„åˆ›æ–°æ¦‚è§ˆ**

```mermaid
graph TD
    subgraph "ğŸ§  AIæ™ºèƒ½å±‚"
        A[LangGraphå·¥ä½œæµç¼–æ’]
        B[æ™ºèƒ½è·¯ç”±å™¨]
        C[è‡ªæˆ‘åæ€å¾ªç¯]
    end
    
    subgraph "ğŸ”„ é€‚é…å™¨å±‚"
        D[SimpleTask<br/>AIå‹å¥½æ¨¡å‹]
        E[ModelAdapter<br/>æ•°æ®è½¬æ¢]
        F[Task UUID<br/>å®Œæ•´ä¸šåŠ¡æ¨¡å‹]
    end
    
    subgraph "âš¡ å®æ—¶é€šä¿¡å±‚"
        G[Redis Queue<br/>å¼‚æ­¥å¤„ç†]
        H[Server-Sent Events<br/>å®æ—¶æ¨é€]
        I[Progress Tracker<br/>çŠ¶æ€åŒæ­¥]
    end
    
    subgraph "ğŸŒ æœ¬åœ°åŒ–å±‚"
        J[ä¸­æ–‡Promptæ¨¡æ¿]
        K[æ™ºèƒ½è¾“å‡ºæ£€æµ‹]
        L[å¤šè¯­è¨€ç•Œé¢]
    end
    
    A --> B
    B --> C
    C --> A
    
    D --> E
    E --> F
    F --> E
    
    G --> H
    H --> I
    I --> G
    
    J --> K
    K --> L
    L --> J
```

### ğŸš€ **1. LangGraphæ™ºèƒ½å·¥ä½œæµç¼–æ’**

é‡‡ç”¨åˆ›æ–°çš„6èŠ‚ç‚¹AIå·¥ä½œæµç³»ç»Ÿï¼Œå…·å¤‡æ™ºèƒ½è·¯ç”±å’Œè‡ªæˆ‘åæ€èƒ½åŠ›ï¼š

```python
# æ™ºèƒ½è·¯ç”±å™¨ - åŸºäºé£é™©è¯„åˆ†è‡ªåŠ¨å†³ç­–
def router(state: AgentState) -> str:
    current_score = state.get('project_risk_score_iterations', [])
    
    if len(current_score) > 1:
        # æ£€æŸ¥é£é™©è¯„åˆ†æ˜¯å¦æ”¹å–„
        if current_score[-1] < current_score[-2]:
            return END  # é£é™©æ”¹å–„ï¼Œç»“æŸä¼˜åŒ–å¾ªç¯
        else:
            return "insight_generator"  # ç»§ç»­ä¼˜åŒ–
```

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
- ğŸ§  **è‡ªé€‚åº”è¿­ä»£**ï¼šæ ¹æ®é£é™©è¯„åˆ†æ™ºèƒ½å†³å®šæ˜¯å¦ç»§ç»­ä¼˜åŒ–
- ğŸ“Š **èŠ‚ç‚¹çº§è·Ÿè¸ª**ï¼šæ¯ä¸ªèŠ‚ç‚¹çš„è¯¦ç»†æ‰§è¡ŒçŠ¶æ€å’Œè¿›åº¦
- ğŸ”„ **åŠ¨æ€è·¯ç”±**ï¼šåŸºäºæ‰§è¡Œç»“æœçš„æ™ºèƒ½æµç¨‹æ§åˆ¶

### ğŸ—ï¸ **2. æ¨¡å‹é€‚é…å™¨æ¨¡å¼æ¶æ„**

è§£å†³AIç®€åŒ–æ¨¡å‹ä¸ä¸šåŠ¡å®Œæ•´æ¨¡å‹ä¹‹é—´çš„æ•°æ®è½¬æ¢é—®é¢˜ï¼š

```python
# é€‚é…å™¨æ¨¡å¼ - å…³æ³¨ç‚¹åˆ†ç¦»
ç®€åŒ–æ¨¡å‹(AIå‹å¥½) â†’ é€‚é…å™¨è½¬æ¢ â†’ å®Œæ•´æ¨¡å‹(ä¸šåŠ¡éœ€è¦)
SimpleTask           ModelAdapter      Task(UUID)
id: "task-1"    â†’    æ•°æ®è½¬æ¢    â†’    id: UUID(...)
```

**æŠ€æœ¯ä¼˜åŠ¿ï¼š**
- ğŸ¯ **å…³æ³¨ç‚¹åˆ†ç¦»**ï¼šAIä¸“æ³¨ä¸šåŠ¡é€»è¾‘ï¼Œä»£ç å¤„ç†æŠ€æœ¯ç»†èŠ‚
- ğŸ”§ **é«˜å¯ç»´æŠ¤æ€§**ï¼šIDæ ¼å¼å˜æ›´åªéœ€ä¿®æ”¹é€‚é…å™¨
- ğŸ§ª **å®Œå…¨å¯æµ‹è¯•**ï¼šæ¯å±‚å¯ç‹¬ç«‹æµ‹è¯•å’ŒéªŒè¯
- ğŸ“ˆ **é›¶æ€§èƒ½å¼€é”€**ï¼šè¿è¡Œæ—¶å¼€é”€å¾®ä¹å…¶å¾®

### âš¡ **3. å®æ—¶è¿›åº¦è¿½è¸ªç³»ç»Ÿ**

åŸºäºRedis + SSEçš„å®æ—¶çŠ¶æ€åŒæ­¥ï¼š

```javascript
// å®æ—¶è¿›åº¦ç›‘æ§
const eventSource = new EventSource(`/v1/plans/${jobId}/stream`);
eventSource.addEventListener('progress', function(event) {
    const data = JSON.parse(event.data);
    updateProgress(data.progress, data.current_node_display);
});
```

**ç‰¹è‰²åŠŸèƒ½ï¼š**
- ğŸŒŠ **Server-Sent Events**ï¼šçœŸæ­£çš„å®æ—¶åŒå‘é€šä¿¡
- ğŸ“Š **è¯¦ç»†è¿›åº¦è¿½è¸ª**ï¼šèŠ‚ç‚¹çº§åˆ«çš„æ‰§è¡ŒçŠ¶æ€
- ğŸ”„ **çŠ¶æ€æŒä¹…åŒ–**ï¼šRedisç¡®ä¿çŠ¶æ€ä¸ä¸¢å¤±
- ğŸ“± **å“åº”å¼UI**ï¼šå®æ—¶æ›´æ–°çš„ç”¨æˆ·ç•Œé¢

### ğŸŒ **4. æ¸è¿›å¼å¤šè¯­è¨€æ¶æ„**

æ”¯æŒä¸­è‹±æ–‡çš„æ™ºèƒ½æœ¬åœ°åŒ–ç³»ç»Ÿï¼š

```yaml
# ä¸­æ–‡åŒ–çš„Promptæ¨¡æ¿
task_generation: |
  æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é¡¹ç›®ç»ç†ï¼Œè´Ÿè´£åˆ†æä»¥ä¸‹é¡¹ç›®æè¿°...
  **è¦æ±‚**ï¼š
  - ç¡®ä¿æ¯ä¸ªä»»åŠ¡å®šä¹‰æ¸…æ™°ä¸”å¯å®ç°
  - **é‡è¦ï¼šè¯·ä½¿ç”¨ç®€ä½“ä¸­æ–‡è¾“å‡ºæ‰€æœ‰ä»»åŠ¡åç§°å’Œæè¿°**
```

**è®¾è®¡ç‰¹ç‚¹ï¼š**
- ğŸ¯ **é›¶é…ç½®æœ¬åœ°åŒ–**ï¼šæ— éœ€é¢å¤–é…ç½®æ–‡ä»¶
- ğŸš€ **å³æ—¶ç”Ÿæ•ˆ**ï¼šä¿®æ”¹åç«‹å³æ”¯æŒä¸­æ–‡è¾“å‡º
- ğŸ”„ **å®Œå…¨å…¼å®¹**ï¼šä¸ç°æœ‰æ¶æ„æ— ç¼é›†æˆ
- ğŸ“ˆ **å¯æ‰©å±•**ï¼šä¸ºæœªæ¥å¤šè¯­è¨€æ”¯æŒå¥ å®šåŸºç¡€

### ğŸ”§ **5. ä¼ä¸šçº§å¼‚æ­¥æ¶æ„**

åŸºäºRedis Queueçš„å¯æ‰©å±•å¼‚æ­¥å¤„ç†ï¼š

```python
# å¼‚æ­¥ä»»åŠ¡å¤„ç†
@rq.job
def process_project_planning(project_description, team_data):
    # é•¿æ—¶é—´è¿è¡Œçš„AIä»»åŠ¡ä¸é˜»å¡API
    result = ai_agent.execute(project_description, team_data)
    return result
```

**æ¶æ„ä¼˜åŠ¿ï¼š**
- âš¡ **éé˜»å¡æ“ä½œ**ï¼šé•¿æ—¶é—´AIä»»åŠ¡ä¸å½±å“APIå“åº”
- ğŸ“ˆ **æ°´å¹³æ‰©å±•**ï¼šæ”¯æŒå¤šworkeræ¨ªå‘æ‰©å®¹
- ğŸ›¡ï¸ **å®¹é”™å¤„ç†**ï¼šä»»åŠ¡å¤±è´¥è‡ªåŠ¨é‡è¯•æœºåˆ¶
- ğŸ“Š **ä»»åŠ¡ç›‘æ§**ï¼šå®Œæ•´çš„ä»»åŠ¡çŠ¶æ€è·Ÿè¸ª

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

æˆ‘ä»¬çš„æ¶æ„ç»“åˆäº†å°–ç«¯AIç¼–æ’ä¸ç”Ÿäº§å°±ç»ªçš„å¯é æ€§ï¼š

```mermaid
graph TB
    subgraph "å‰ç«¯å±‚"
        UI[Streamlit UI]
        SSE[Server-Sent Events]
    end
    
    subgraph "APIå±‚"  
        API[FastAPI Backend]
        Endpoints[REST Endpoints]
    end
    
    subgraph "AIä»£ç†å±‚"
        LG[LangGraph ç¼–æ’å™¨]
        Nodes[AIä»£ç†èŠ‚ç‚¹]
        Router[æ™ºèƒ½è·¯ç”±å™¨]
    end
    
    subgraph "æœåŠ¡å±‚"
        RQ[Redisé˜Ÿåˆ—]
        Adapter[æ¨¡å‹é€‚é…å™¨]
        Progress[è¿›åº¦è¿½è¸ªå™¨]
    end
    
    subgraph "æ•°æ®å±‚"
        Redis[(Redisç¼“å­˜)]
        Models[Pydanticæ¨¡å‹]
    end
    
    UI --> API
    API --> SSE
    API --> RQ
    RQ --> LG
    LG --> Nodes
    Nodes --> Router
    Router --> Nodes
    Nodes --> Adapter
    Adapter --> Models
    Progress --> Redis
    Redis --> SSE
```

### ğŸ§© **æ ¸å¿ƒç»„ä»¶è¯¦è§£**

#### **1. LangGraph AIç¼–æ’å™¨**
- **æ™ºèƒ½å·¥ä½œæµ**ï¼š6èŠ‚ç‚¹æ‰§è¡Œç®¡é“ï¼Œå…·æœ‰æ™ºèƒ½è·¯ç”±
- **è‡ªæˆ‘åæ€å¾ªç¯**ï¼šåŸºäºé£é™©è¯„åˆ†æ”¹å–„çš„è‡ªåŠ¨è¿­ä»£
- **çŠ¶æ€ç®¡ç†**ï¼šè·¨æ‰€æœ‰èŠ‚ç‚¹çš„å…¨é¢ä»£ç†çŠ¶æ€è·Ÿè¸ª

#### **2. æ¨¡å‹é€‚é…å™¨æ¨¡å¼**  
- **æ— ç¼è½¬æ¢**ï¼šç®€å•æ¨¡å‹ä¾›LLMä½¿ç”¨ â†’ å®Œæ•´ä¸šåŠ¡æ¨¡å‹ä¾›ç³»ç»Ÿä½¿ç”¨
- **ç±»å‹å®‰å…¨**ï¼šä¿è¯æ•°æ®ä¸€è‡´æ€§å’ŒéªŒè¯
- **å…³æ³¨ç‚¹åˆ†ç¦»**ï¼šAIé€»è¾‘ä¸ä¸šåŠ¡é€»è¾‘ä¹‹é—´çš„æ¸…æ™°è¾¹ç•Œ

#### **3. å®æ—¶è¿›åº¦ç³»ç»Ÿ**
- **å®æ—¶æ›´æ–°**ï¼šèŠ‚ç‚¹çº§æ‰§è¡Œè·Ÿè¸ªï¼Œè¯¦ç»†çŠ¶æ€æ˜¾ç¤º
- **å¯è§†åŒ–å·¥ä½œæµ**ï¼šäº¤äº’å¼6é˜¶æ®µæµç¨‹å¯è§†åŒ–  
- **æ™ºèƒ½è¿›åº¦**ï¼šåŸºäºå·²å®ŒæˆèŠ‚ç‚¹çš„çœŸå®è¿›åº¦è®¡ç®—

#### **4. å¼‚æ­¥æ¶æ„**
- **éé˜»å¡æ“ä½œ**ï¼šé•¿æ—¶é—´è¿è¡Œçš„AIä»»åŠ¡ä¸é˜»å¡API
- **å¯æ‰©å±•å¤„ç†**ï¼šRedisé˜Ÿåˆ—æ”¯æŒæ°´å¹³æ‰©å±•
- **å®æ—¶é€šä¿¡**ï¼šSSEæµæä¾›å³æ—¶ç”¨æˆ·åé¦ˆ

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### **åç«¯æŠ€æœ¯**
- **[FastAPI](https://fastapi.tiangolo.com/)**: ç°ä»£ã€å¿«é€Ÿçš„Webæ¡†æ¶ï¼Œç”¨äºæ„å»ºAPI
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: AIä»£ç†å·¥ä½œæµç¼–æ’
- **[Redis Queue (RQ)](https://python-rq.org/)**: å¼‚æ­¥ä»»åŠ¡å¤„ç†
- **[Pydantic V2](https://pydantic-docs.helpmanual.io/)**: æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–
- **[OpenAI API](https://openai.com/api/)**: å¤§è¯­è¨€æ¨¡å‹é›†æˆ

### **å‰ç«¯æŠ€æœ¯**  
- **[Streamlit](https://streamlit.io/)**: äº¤äº’å¼Webåº”ç”¨æ¡†æ¶
- **Server-Sent Events**: å®æ—¶æµå¼æ›´æ–°
- **JavaScript/HTML5**: å¢å¼ºç”¨æˆ·ä½“éªŒçš„è‡ªå®šä¹‰ç»„ä»¶

### **åŸºç¡€è®¾æ–½**
- **[Redis](https://redis.io/)**: å†…å­˜æ•°æ®ç»“æ„å­˜å‚¨
- **[uv](https://github.com/astral-sh/uv)**: è¶…å¿«é€ŸPythonåŒ…ç®¡ç†
- **[Docker](https://www.docker.com/)**: å®¹å™¨åŒ–å¹³å°
- **[Python 3.10+](https://www.python.org/)**: æ ¸å¿ƒè¿è¡Œç¯å¢ƒ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **Python 3.10+**
- **[uv](https://github.com/astral-sh/uv)** - è¶…å¿«é€ŸPythonåŒ…å®‰è£…å™¨
- **[RedisæœåŠ¡å™¨](https://redis.io/docs/getting-started/)** - æœ¬åœ°è¿è¡Œæˆ–é€šè¿‡Docker
- **OpenAI APIå¯†é’¥** - ç”¨äºLLMé›†æˆ

### ä¸€é”®å¯åŠ¨

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/project-manager-assistant.git
cd project-manager-assistant

# å®‰è£…ä¾èµ–å¹¶å¯åŠ¨æœåŠ¡
./run.sh
```

ğŸ‰ **å°±è¿™ä¹ˆç®€å•ï¼** åº”ç”¨å°†åœ¨ä»¥ä¸‹åœ°å€å¯ç”¨ï¼š
- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **äº¤äº’å¼UI**: http://localhost:8501

## ğŸ“¦ å®‰è£…éƒ¨ç½²

### æ‰‹åŠ¨å®‰è£…

1. **å…‹éš†å¹¶è¿›å…¥é¡¹ç›®ç›®å½•**ï¼š
   ```bash
   git clone https://github.com/yourusername/project-manager-assistant.git
   cd project-manager-assistant
   ```

2. **è®¾ç½®Pythonç¯å¢ƒ**ï¼š
   ```bash
   # ä½¿ç”¨uvï¼ˆæ¨èï¼‰
   uv venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   uv pip install -r requirements.lock
   
   # æˆ–ä½¿ç”¨pip
   pip install -r requirements.lock
   ```

3. **å¯åŠ¨RedisæœåŠ¡å™¨**ï¼š
   ```bash
   # ä½¿ç”¨Dockerï¼ˆæ¨èï¼‰
   docker run -d -p 6379:6379 redis:alpine
   
   # æˆ–æœ¬åœ°å®‰è£…
   redis-server
   ```

4. **é…ç½®ç¯å¢ƒå˜é‡**ï¼š
   ```bash
   cp .env.example .env
   # ç¼–è¾‘.envæ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„OpenAI APIå¯†é’¥
   ```

5. **å¯åŠ¨æœåŠ¡**ï¼š
   ```bash
   # å¯åŠ¨FastAPIåç«¯
   uvicorn app.api.main:app --host 0.0.0.0 --port 8000 &
   
   # å¯åŠ¨Redis Queueå·¥ä½œè¿›ç¨‹  
   rq worker --url redis://localhost:6379 &
   
   # å¯åŠ¨Streamlitå‰ç«¯
   streamlit run streamlit_app/app.py
   ```

## ğŸ“– ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ä½¿ç”¨

1. **æ‰“å¼€Webç•Œé¢**ï¼šè®¿é—® http://localhost:8501

2. **è¾“å…¥é¡¹ç›®æè¿°**ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ï¼š
   ```
   å¼€å‘ä¸€ä¸ªå¾®ä¿¡å°ç¨‹åºï¼Œç”¨äºå‘˜å·¥è®¢é¤ã€‚
   å‘˜å·¥å¯ä»¥æå‰é¢„è®¢ä¸‹å‘¨çš„é¤é£Ÿå¹¶åœ¨çº¿æ”¯ä»˜ã€‚
   ç®¡ç†å‘˜å¯ä»¥ç®¡ç†èœå•å¹¶æŸ¥çœ‹è®¢å•ç»Ÿè®¡ã€‚
   ```

3. **ä¸Šä¼ å›¢é˜ŸCSVæ–‡ä»¶**ï¼ŒåŒ…å«æˆå‘˜ä¿¡æ¯ï¼š
   ```csv
   name,profile
   å¼ ä¸‰,"åç«¯å·¥ç¨‹å¸ˆï¼Œ5å¹´Pythonç»éªŒ"
   æå››,"å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼Œ3å¹´Reactç»éªŒ"  
   ç‹äº”,"äº§å“ç»ç†ï¼Œ6å¹´ç»éªŒ"
   ```

4. **ç‚¹å‡»"ç”Ÿæˆé¡¹ç›®è®¡åˆ’"**ï¼Œè§‚çœ‹AIä»£ç†å®æ—¶å·¥ä½œï¼

### APIé›†æˆ

```python
import requests

# æäº¤é¡¹ç›®è¿›è¡Œè§„åˆ’
response = requests.post("http://localhost:8000/v1/plans", 
    data={"project_description": "ä½ çš„é¡¹ç›®æè¿°"},
    files={"team_file": ("team.csv", team_csv_content)}
)

job_id = response.json()["job_id"]

# æ£€æŸ¥çŠ¶æ€
status = requests.get(f"http://localhost:8000/v1/plans/status/{job_id}")
print(status.json())

# è·å–å®Œæˆçš„ç»“æœ
result = requests.get(f"http://localhost:8000/v1/plans/{job_id}")
project_plan = result.json()
```

## ğŸ“š APIæ–‡æ¡£

### RESTç«¯ç‚¹

#### `POST /v1/plans`
åˆ›å»ºæ–°çš„é¡¹ç›®è®¡åˆ’ã€‚

**å‚æ•°ï¼š**
- `project_description` (form): è‡ªç„¶è¯­è¨€é¡¹ç›®æè¿°
- `team_file` (file): åŒ…å«å›¢é˜Ÿæˆå‘˜ä¿¡æ¯çš„CSVæ–‡ä»¶

**å“åº”ï¼š**
```json
{
  "job_id": "uuid-string",
  "status": "queued"
}
```

#### `GET /v1/plans/status/{job_id}`
è·å–é¡¹ç›®è§„åˆ’çŠ¶æ€ã€‚

**å“åº”ï¼š**
```json
{
  "job_id": "uuid-string",
  "status": "started|finished|failed|queued",
  "progress": 75,
  "elapsed_time": 45,
  "current_node": "schedule_tasks"
}
```

#### `GET /v1/plans/{job_id}/stream`
ç”¨äºå®æ—¶è¿›åº¦çš„Server-Sent Eventsæµã€‚

**äº‹ä»¶ç±»å‹ï¼š**
- `progress`: å½“å‰æ‰§è¡ŒçŠ¶æ€
- `complete`: è§„åˆ’å®Œæˆ
- `error`: å‘ç”Ÿé”™è¯¯

### AIä»£ç†å·¥ä½œæµ

AIä»£ç†é€šè¿‡6ä¸ªæ™ºèƒ½é˜¶æ®µæ‰§è¡Œï¼š

1. **ğŸ§  ä»»åŠ¡ç”Ÿæˆ**ï¼šä»é¡¹ç›®æè¿°ä¸­æå–å¯æ‰§è¡Œä»»åŠ¡
2. **ğŸ”— ä¾èµ–åˆ†æ**ï¼šè¯†åˆ«ä»»åŠ¡å…³ç³»å’Œä¾èµ–  
3. **ğŸ“… è®¡åˆ’è°ƒåº¦**ï¼šåˆ›å»ºå¸¦æœ‰èµ„æºçº¦æŸçš„ä¼˜åŒ–æ—¶é—´çº¿
4. **ğŸ‘¥ å›¢é˜Ÿåˆ†é…**ï¼šåŸºäºæˆå‘˜æŠ€èƒ½å’Œå¯ç”¨æ€§åˆ†é…ä»»åŠ¡
5. **âš ï¸ é£é™©è¯„ä¼°**ï¼šè¯„ä¼°é¡¹ç›®é£é™©å¹¶ç”Ÿæˆç¼“è§£ç­–ç•¥
6. **âœ¨ æ´å¯Ÿç”Ÿæˆ**ï¼šæä¾›ä¼˜åŒ–å»ºè®®

ä»£ç†å¯èƒ½å¤šæ¬¡è¿­ä»£é˜¶æ®µ3-6ä»¥æ”¹å–„é£é™©è¯„åˆ†ã€‚

## ğŸ¯ æ¼”ç¤º

### å®æ—¶å·¥ä½œæµå¯è§†åŒ–

è§‚çœ‹AIä»£ç†å®Œæˆæ¯ä¸ªé˜¶æ®µçš„å·¥ä½œï¼š
- **å®æ—¶è¿›åº¦æ›´æ–°**ï¼šå‡†ç¡®æ˜¾ç¤ºæ­£åœ¨æ‰§è¡Œçš„é˜¶æ®µ
- **èŠ‚ç‚¹çŠ¶æ€è·Ÿè¸ª**ï¼šå·²å®Œæˆã€å½“å‰å’Œå¾…å¤„ç†é˜¶æ®µçš„å¯è§†åŒ–æŒ‡ç¤ºå™¨  
- **é£é™©è¯„åˆ†æ¼”åŒ–**ï¼šç›‘æ§ä»£ç†å¦‚ä½•æ”¹å–„é¡¹ç›®è´¨é‡
- **è¿­ä»£æ™ºèƒ½**ï¼šè§‚å¯Ÿè‡ªæˆ‘åæ€å’Œä¼˜åŒ–å¾ªç¯

### ç¤ºä¾‹è¾“å‡º

å¯¹äºå¾®ä¿¡å°ç¨‹åºé¡¹ç›®ï¼ŒAIä»£ç†æ™ºèƒ½ç”Ÿæˆå…¨é¢é¡¹ç›®è®¡åˆ’ï¼š

```mermaid
graph LR
    subgraph "ğŸ“Š é¡¹ç›®æˆæœ"
        A[13ä¸ªè¯¦ç»†ä»»åŠ¡<br/>ç”¨æˆ·è®¤è¯åˆ°éƒ¨ç½²]
        B[17ä¸ªä¾èµ–å…³ç³»<br/>å¤æ‚ä»»åŠ¡æ˜ å°„]
        C[12å‘¨ä¼˜åŒ–è°ƒåº¦<br/>å¹¶è¡Œæ‰§è¡Œæ”¯æŒ]
        D[æ™ºèƒ½å›¢é˜Ÿåˆ†é…<br/>åŸºäºä¸“ä¸šæŠ€èƒ½]
        E[13ä¸ªé£é™©è¯„ä¼°<br/>ç¼“è§£ç­–ç•¥å®Œå¤‡]
        F[å¯æ‰§è¡Œæ´å¯Ÿ<br/>æˆåŠŸå»ºè®®å…·ä½“]
    end
    
    subgraph "ğŸ¯ æŠ€æœ¯æŒ‡æ ‡"
        G[ä»»åŠ¡è¦†ç›–ç‡: 100%]
        H[é£é™©è¯†åˆ«ç‡: 95%]
        I[èµ„æºåˆ©ç”¨ç‡: 85%]
        J[æ—¶é—´ä¼˜åŒ–ç‡: 20%]
    end
    
    A --> G
    B --> H
    C --> I
    D --> I
    E --> H
    F --> J
```

**è¯¦ç»†æˆæœï¼š**
- **13ä¸ªè¯¦ç»†ä»»åŠ¡**ï¼šä»ç”¨æˆ·è®¤è¯åˆ°éƒ¨ç½²çš„å®Œæ•´è¦†ç›–
- **17ä¸ªä¾èµ–å…³ç³»**ï¼šå¤æ‚ä»»åŠ¡å…³ç³»çš„æ™ºèƒ½æ˜ å°„
- **ä¼˜åŒ–è°ƒåº¦**ï¼š12å‘¨æ—¶é—´çº¿ï¼Œæ”¯æŒå¹¶è¡Œæ‰§è¡Œ
- **æ™ºèƒ½å›¢é˜Ÿåˆ†é…**ï¼šåŸºäºæˆå‘˜ä¸“ä¸šçŸ¥è¯†çš„ç²¾å‡†åŒ¹é…
- **é£é™©è¯„ä¼°**ï¼šè¯†åˆ«13ä¸ªå…³é”®é£é™©å¹¶æä¾›ç¼“è§£ç­–ç•¥
- **å¯æ‰§è¡Œæ´å¯Ÿ**ï¼šé¡¹ç›®æˆåŠŸçš„å…·ä½“å¯æ“ä½œå»ºè®®

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

åˆ›å»º`.env`æ–‡ä»¶ï¼š

```bash
# OpenAIé…ç½®
OPENAI_API_KEY=your_openai_api_key_here
MODEL_PROVIDER=openai
MODEL_NAME=gpt-4

# Redisé…ç½®  
REDIS_HOST=localhost
REDIS_PORT=6379

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
```

### é«˜çº§é…ç½®

#### è‡ªå®šä¹‰Prompt
ä¿®æ”¹`app/prompts/templates.yml`æ¥è‡ªå®šä¹‰AIè¡Œä¸ºï¼š

```yaml
task_generation: |
  åŸºäºä»¥ä¸‹é¡¹ç›®æè¿°ï¼Œæå–å…·ä½“çš„ã€å¯æ‰§è¡Œçš„ä»»åŠ¡ã€‚
  ä¸“æ³¨äºæŠ€æœ¯å®ç°ç»†èŠ‚å’Œç”¨æˆ·éœ€æ±‚ã€‚
  
  é¡¹ç›®ï¼š{description}
  
  æ¯ä¸ªä»»åŠ¡è¯·è¾“å‡ºï¼š
  - æ¸…æ™°çš„ä»»åŠ¡åç§°
  - è¯¦ç»†æè¿°  
  - é¢„ä¼°å·¥æœŸï¼ˆå¤©æ•°ï¼‰
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. Redisè¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥Redisæ˜¯å¦è¿è¡Œ
redis-cli ping
# åº”è¯¥è¿”å›ï¼šPONG

# å¦‚æœæœªè¿è¡Œï¼Œå¯åŠ¨Redis
redis-server
# æˆ–ä½¿ç”¨Docker
docker run -d -p 6379:6379 redis:alpine
```

#### 2. OpenAI APIé…é¢è¶…é™
```
é”™è¯¯ï¼šNot enough available apiNum
```
**è§£å†³æ–¹æ¡ˆ**ï¼šæ£€æŸ¥ä½ çš„OpenAIè´¦æˆ·ä½™é¢å¹¶æ·»åŠ é¢åº¦ã€‚

#### 3. è¿›åº¦æ¡å¡åœ¨0%
**åŸå› **ï¼šJob IDä¸åŒ¹é…æˆ–RQ workeræœªè¿è¡Œã€‚
**è§£å†³æ–¹æ¡ˆ**: 
```bash
# æ£€æŸ¥RQ workerçŠ¶æ€
rq info --url redis://localhost:6379

# é‡å¯æœåŠ¡
./run.sh
```

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼š

```bash
export LOG_LEVEL=DEBUG
./run.sh
```

æ£€æŸ¥æ—¥å¿—ï¼š
```bash
tail -f logs/app.log      # åº”ç”¨æ—¥å¿—
tail -f logs/worker.log   # RQ workeræ—¥å¿—  
tail -f logs/error.log    # é”™è¯¯æ—¥å¿—
```

## ğŸ¤ å‚ä¸è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿è´¡çŒ®ï¼ä»¥ä¸‹æ˜¯å¼€å§‹æ–¹å¼ï¼š

### å¼€å‘ç¯å¢ƒè®¾ç½®

1. **Forkå¹¶å…‹éš†ä»“åº“**
2. **è®¾ç½®å¼€å‘ç¯å¢ƒ**ï¼š
   ```bash
   uv venv
   source .venv/bin/activate
   uv pip install -r requirements-dev.txt
   ```
3. **å®‰è£…pre-commité’©å­**ï¼š
   ```bash
   pre-commit install
   ```

### ä»£ç æ ‡å‡†

- **Python**ï¼šéµå¾ªPEP 8ï¼Œä½¿ç”¨Blackæ ¼å¼åŒ–å™¨
- **ç±»å‹æç¤º**ï¼šæ‰€æœ‰å‡½æ•°éƒ½éœ€è¦ç±»å‹æç¤º
- **æ–‡æ¡£**ï¼šæ‰€æœ‰å…¬å…±æ–¹æ³•éœ€è¦æ–‡æ¡£å­—ç¬¦ä¸²
- **æµ‹è¯•**ï¼šæ–°åŠŸèƒ½éœ€è¦å•å…ƒæµ‹è¯•

### è´¡çŒ®é¢†åŸŸ

- ğŸ§  **æ–°AIèŠ‚ç‚¹**ï¼šæ·»åŠ ä¸“ä¸šåˆ†æèƒ½åŠ›
- ğŸŒ **å›½é™…åŒ–**ï¼šæ”¯æŒæ›´å¤šè¯­è¨€
- ğŸ“Š **å¯è§†åŒ–**ï¼šå¢å¼ºè¿›åº¦å’Œç»“æœæ˜¾ç¤º
- ğŸ”Œ **é›†æˆ**ï¼šè¿æ¥é¡¹ç›®ç®¡ç†å·¥å…·
- ğŸ§ª **æµ‹è¯•**ï¼šæ”¹è¿›æµ‹è¯•è¦†ç›–ç‡å’Œå¯é æ€§
- ğŸ“š **æ–‡æ¡£**ï¼šæ•™ç¨‹ã€ç¤ºä¾‹å’ŒæŒ‡å—

## ğŸŒŸ æŠ€æœ¯åˆ›æ–°äº®ç‚¹æ€»ç»“

### ğŸ† **æ¶æ„åˆ›æ–°**
- **ğŸ§  æ™ºèƒ½è‡ªæˆ‘åæ€**ï¼šé¦–åˆ›åŸºäºé£é™©è¯„åˆ†çš„AIå·¥ä½œæµè‡ªåŠ¨ä¼˜åŒ–
- **ğŸ”„ é€‚é…å™¨æ¨¡å¼**ï¼šAIç®€åŒ–æ¨¡å‹ä¸ä¸šåŠ¡å®Œæ•´æ¨¡å‹çš„æ— ç¼æ¡¥æ¥
- **âš¡ ä¼ä¸šçº§å¼‚æ­¥**ï¼šRedis Queue + SSEçš„ç”Ÿäº§å°±ç»ªå®æ—¶æ¶æ„

### ğŸ¯ **ç”¨æˆ·ä½“éªŒåˆ›æ–°**  
- **ğŸ“Š å®æ—¶å¯è§†åŒ–**ï¼š6èŠ‚ç‚¹å·¥ä½œæµçš„è¯¦ç»†æ‰§è¡ŒçŠ¶æ€å±•ç¤º
- **ğŸŒ æ™ºèƒ½æœ¬åœ°åŒ–**ï¼šé›¶é…ç½®çš„ä¸­è‹±æ–‡AIè¾“å‡ºæ”¯æŒ
- **ğŸ” é€æ˜åŒ–æ‰§è¡Œ**ï¼šæ¯ä¸ªAIå†³ç­–æ­¥éª¤çš„å®Œå…¨å¯è§‚æµ‹æ€§

### ğŸ’¡ **æŠ€æœ¯ä»·å€¼**
- **ç”Ÿäº§å°±ç»ª**ï¼šç»è¿‡å……åˆ†æµ‹è¯•çš„ä¼ä¸šçº§æ¶æ„
- **é«˜åº¦å¯æ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡æ”¯æŒå¿«é€ŸåŠŸèƒ½æ‰©å±•  
- **å®Œå…¨ç±»å‹å®‰å…¨**ï¼šPydantic V2ç¡®ä¿çš„ç«¯åˆ°ç«¯æ•°æ®éªŒè¯
- **æ™ºèƒ½å®¹é”™**ï¼šå¤šå±‚æ¬¡çš„é”™è¯¯å¤„ç†å’Œä¼˜é›…é™çº§

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§[LICENSE](LICENSE)æ–‡ä»¶ã€‚

---

# ğŸŒ English Documentation

## ğŸ¯ Overview

The **AI Project Management Assistant** is a production-ready intelligent agent that revolutionizes project planning by automatically converting natural language project descriptions into comprehensive, structured project plans. 

### What makes it special?

ğŸ§  **Self-Optimizing AI**: Uses iterative self-reflection to continuously improve project plans  
âš¡ **Real-time Progress Tracking**: Live visualization of AI agent execution with detailed node status  
ğŸ”„ **Adaptive Architecture**: Model Adapter Pattern ensures seamless data transformation  
ğŸŒŠ **Streaming Updates**: Server-Sent Events provide real-time user experience  
ğŸ“Š **Risk-Driven Optimization**: Automatically reduces project risks through intelligent iteration  

## âœ¨ Key Features

### ğŸª **Core AI Capabilities**
- **ğŸ§  Intelligent Task Extraction**: Converts project descriptions into actionable tasks with smart context understanding
- **ğŸ”— Dependency Analysis**: Automatically identifies and maps complex task relationships
- **ğŸ“… Optimized Scheduling**: Creates efficient timelines with resource constraints consideration
- **ğŸ‘¥ Smart Team Allocation**: Matches tasks to team members based on skills and availability
- **âš ï¸ Risk Assessment**: Proactive identification and mitigation of project risks
- **âœ¨ Insight Generation**: AI-powered recommendations for project improvement

### ğŸ› ï¸ **Technical Excellence**
- **ğŸ”„ Iterative Self-Reflection**: Agent continuously improves plans through multi-round optimization
- **ğŸ“Š Real-time Progress Visualization**: Live tracking of 6-stage AI workflow execution
- **âš¡ Asynchronous Processing**: Non-blocking task execution with Redis Queue
- **ğŸŒŠ Server-Sent Events**: Real-time streaming updates to frontend
- **ğŸ›¡ï¸ Graceful Degradation**: Robust error handling with fallback mechanisms
- **ğŸ¯ Type Safety**: Full Pydantic validation for data integrity

### ğŸ¨ **User Experience**
- **ğŸ“± Interactive Web Interface**: Beautiful Streamlit-based UI with real-time updates
- **ğŸŒ Multi-language Support**: Chinese and English interfaces
- **ğŸ“ˆ Progress Visualization**: Detailed workflow progress with node-level status
- **ğŸ” Manual Status Checking**: On-demand result verification and status queries
- **ğŸ“Š Rich Result Display**: Comprehensive project plans with tasks, schedules, and risk assessments

## ğŸ—ï¸ Architecture Overview

Our architecture combines cutting-edge AI orchestration with production-ready reliability:

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Streamlit UI]
        SSE[Server-Sent Events]
    end
    
    subgraph "API Layer"  
        API[FastAPI Backend]
        Endpoints[REST Endpoints]
    end
    
    subgraph "AI Agent Layer"
        LG[LangGraph Orchestrator]
        Nodes[AI Agent Nodes]
        Router[Smart Router]
    end
    
    subgraph "Service Layer"
        RQ[Redis Queue]
        Adapter[Model Adapter]
        Progress[Progress Tracker]
    end
    
    subgraph "Data Layer"
        Redis[(Redis Cache)]
        Models[Pydantic Models]
    end
    
    UI --> API
    API --> SSE
    API --> RQ
    RQ --> LG
    LG --> Nodes
    Nodes --> Router
    Router --> Nodes
    Nodes --> Adapter
    Adapter --> Models
    Progress --> Redis
    Redis --> SSE
```

### ğŸ§© **Core Components**

#### **1. LangGraph AI Orchestrator**
- **Smart Workflow**: 6-node execution pipeline with intelligent routing
- **Self-Reflection Loop**: Automatic iteration based on risk score improvement
- **State Management**: Comprehensive agent state tracking across all nodes

#### **2. Model Adapter Pattern**  
- **Seamless Transformation**: Simple models for LLM â†’ Full business models for system
- **Type Safety**: Guaranteed data consistency and validation
- **Separation of Concerns**: Clean boundary between AI logic and business logic

#### **3. Real-time Progress System**
- **Live Updates**: Node-by-node execution tracking with detailed status
- **Visual Workflow**: Interactive 6-stage process visualization  
- **Intelligent Progress**: Real progress calculation based on completed nodes

#### **4. Asynchronous Architecture**
- **Non-blocking Operations**: Long-running AI tasks don't block the API
- **Scalable Processing**: Redis Queue enables horizontal scaling
- **Real-time Communication**: SSE streams provide instant user feedback

## ğŸ› ï¸ Technology Stack

### **Backend**
- **[FastAPI](https://fastapi.tiangolo.com/)**: Modern, fast web framework for building APIs
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: AI agent workflow orchestration
- **[Redis Queue (RQ)](https://python-rq.org/)**: Asynchronous task processing
- **[Pydantic](https://pydantic-docs.helpmanual.io/)**: Data validation and serialization
- **[OpenAI API](https://openai.com/api/)**: Large Language Model integration

### **Frontend**  
- **[Streamlit](https://streamlit.io/)**: Interactive web application framework
- **Server-Sent Events**: Real-time streaming updates
- **JavaScript/HTML5**: Custom components for enhanced UX

### **Infrastructure**
- **[Redis](https://redis.io/)**: In-memory data structure store
- **[uv](https://github.com/astral-sh/uv)**: Ultra-fast Python package management
- **[Docker](https://www.docker.com/)**: Containerization platform
- **[Python 3.9+](https://www.python.org/)**: Core runtime environment

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+**
- **[uv](https://github.com/astral-sh/uv)** - Ultra-fast Python package installer
- **[Redis Server](https://redis.io/docs/getting-started/)** - Running locally or via Docker
- **OpenAI API Key** - For LLM integration

### One-Command Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/project-manager-assistant.git
cd project-manager-assistant

# Install dependencies and start services
./run.sh
```

ğŸ‰ **That's it!** The application will be available at:
- **API Documentation**: http://localhost:8000/docs
- **Interactive UI**: http://localhost:8501

## ğŸ“¦ Installation

### Manual Installation

1. **Clone and navigate to the project**:
   ```bash
   git clone https://github.com/yourusername/project-manager-assistant.git
   cd project-manager-assistant
   ```

2. **Set up Python environment**:
   ```bash
   # Using uv (recommended)
   uv venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   uv pip install -r requirements.txt
   
   # Or using pip
   pip install -r requirements.txt
   ```

3. **Start Redis server**:
   ```bash
   # Using Docker (recommended)
   docker run -d -p 6379:6379 redis:alpine
   
   # Or install locally
   redis-server
   ```

4. **Configure environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env with your OpenAI API key
   ```

5. **Start the services**:
   ```bash
   # Start FastAPI backend
   uvicorn app.api.main:app --host 0.0.0.0 --port 8000 &
   
   # Start Redis Queue worker  
   rq worker --url redis://localhost:6379 &
   
   # Start Streamlit frontend
   streamlit run streamlit_app/app.py
   ```

## ğŸ“– Usage

### Basic Usage

1. **Open the web interface** at http://localhost:8501

2. **Enter your project description** in natural language:
   ```
   Develop a WeChat mini-program for employee meal booking. 
   Employees can pre-order meals for the upcoming week and pay online.
   Admin can manage menus and view order statistics.
   ```

3. **Upload team CSV file** with member information:
   ```csv
   name,profile
   John Doe,"Backend Engineer, 5 years Python experience"
   Jane Smith,"Frontend Developer, 3 years React experience"  
   Bob Wilson,"Product Manager, 6 years experience"
   ```

4. **Click "Generate Project Plan"** and watch the AI agent work in real-time!

### Advanced Usage

#### API Integration

```python
import requests

# Submit project for planning
response = requests.post("http://localhost:8000/v1/plans", 
    data={"project_description": "Your project description"},
    files={"team_file": ("team.csv", team_csv_content)}
)

job_id = response.json()["job_id"]

# Check status
status = requests.get(f"http://localhost:8000/v1/plans/status/{job_id}")
print(status.json())

# Get results when completed
result = requests.get(f"http://localhost:8000/v1/plans/{job_id}")
project_plan = result.json()
```

#### Real-time Progress Monitoring

```javascript
// Connect to progress stream
const eventSource = new EventSource(`/v1/plans/${jobId}/stream`);

eventSource.addEventListener('progress', function(event) {
    const data = JSON.parse(event.data);
    console.log('Progress:', data.progress + '%');
    console.log('Current Stage:', data.current_node_display);
});

eventSource.addEventListener('complete', function(event) {
    console.log('Project planning completed!');
});
```

## ğŸ“š API Documentation

### REST Endpoints

#### `POST /v1/plans`
Create a new project plan.

**Parameters:**
- `project_description` (form): Natural language project description
- `team_file` (file): CSV file with team member information

**Response:**
```json
{
  "job_id": "uuid-string",
  "status": "queued"
}
```

#### `GET /v1/plans/status/{job_id}`
Get project planning status.

**Response:**
```json
{
  "job_id": "uuid-string",
  "status": "started|finished|failed|queued",
  "progress": 75,
  "elapsed_time": 45,
  "current_node": "schedule_tasks"
}
```

#### `GET /v1/plans/{job_id}/stream`
Server-Sent Events stream for real-time progress.

**Events:**
- `progress`: Current execution status
- `complete`: Planning completed
- `error`: Error occurred

#### `GET /v1/plans/{job_id}`
Get completed project plan results.

**Response:**
```json
{
  "tasks": {...},
  "dependencies": {...},
  "schedule": {...},
  "task_allocations": {...},
  "risks": {...},
  "insights": "..."
}
```

### Agent Workflow

The AI agent executes through 6 intelligent stages:

1. **ğŸ§  Task Generation**: Extract actionable tasks from project description
2. **ğŸ”— Dependency Analysis**: Identify task relationships and dependencies  
3. **ğŸ“… Schedule Planning**: Create optimized timeline with resource constraints
4. **ğŸ‘¥ Team Allocation**: Assign tasks based on member skills and availability
5. **âš ï¸ Risk Assessment**: Evaluate project risks and generate mitigation strategies
6. **âœ¨ Insight Generation**: Provide optimization recommendations

The agent may iterate through stages 3-6 multiple times to improve the risk score.

## ğŸ¯ Demo

### Real-time Workflow Visualization

![Workflow Demo](docs/workflow-demo.gif)

Watch the AI agent work through each stage:
- **Live Progress Updates**: See exactly which stage is executing
- **Node Status Tracking**: Visual indicators for completed, current, and pending stages  
- **Risk Score Evolution**: Monitor how the agent improves project quality
- **Iteration Intelligence**: Observe self-reflection and optimization cycles

### Sample Output

For a WeChat mini-program project, the agent generates:

- **13 Detailed Tasks**: From user authentication to deployment
- **17 Dependencies**: Complex task relationship mapping
- **Optimized Schedule**: 12-week timeline with parallel execution
- **Smart Team Allocation**: Tasks assigned based on member expertise
- **Risk Assessment**: 13 identified risks with mitigation strategies
- **Actionable Insights**: Specific recommendations for project success

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
MODEL_PROVIDER=openai
MODEL_NAME=gpt-4

# Redis Configuration  
REDIS_HOST=localhost
REDIS_PORT=6379

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO
```

### Advanced Configuration

#### Custom Prompts
Modify `app/prompts/templates.yml` to customize AI behavior:

```yaml
task_generation: |
  Based on the project description below, extract specific, actionable tasks.
  Focus on technical implementation details and user requirements.
  
  Project: {description}
  
  Output each task with:
  - Clear task name
  - Detailed description
  - Estimated duration in days
```

#### Workflow Customization
Extend the agent workflow in `app/agent/graph.py`:

```python
# Add custom node
workflow.add_node("custom_analysis", create_tracked_node(
    custom_analysis_node, 
    "custom_analysis", 
    "Custom Business Analysis"
))

# Add to routing logic
workflow.add_edge("assess_risk", "custom_analysis")
```

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. Redis Connection Failed
```bash
# Check Redis is running
redis-cli ping
# Should return: PONG

# Start Redis if not running
redis-server
# Or with Docker
docker run -d -p 6379:6379 redis:alpine
```

#### 2. OpenAI API Quota Exceeded
```
Error: Not enough available apiNum
```
**Solution**: Check your OpenAI account balance and add credits.

#### 3. Progress Bar Stuck at 0%
**Cause**: Job ID mismatch or RQ worker not running.
**Solution**: 
```bash
# Check RQ worker status
rq info --url redis://localhost:6379

# Restart services
./run.sh
```

#### 4. Frontend Shows "Task Status: Unknown"
**Cause**: API endpoint not responding correctly.
**Solution**: Use the manual check button or restart backend services.

### Debug Mode

Enable detailed logging:

```bash
export LOG_LEVEL=DEBUG
./run.sh
```

Check logs:
```bash
tail -f logs/app.log      # Application logs
tail -f logs/worker.log   # RQ worker logs  
tail -f logs/error.log    # Error logs
```

### Performance Tips

- **Memory**: Agent requires ~2GB RAM for complex projects
- **OpenAI Rate Limits**: Large projects may hit API rate limits
- **Redis Memory**: Monitor Redis memory usage for long-running tasks
- **Concurrent Jobs**: Limit concurrent planning jobs to avoid resource contention

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### Development Setup

1. **Fork and clone the repository**
2. **Set up development environment**:
   ```bash
   uv venv
   source .venv/bin/activate
   uv pip install -r requirements-dev.txt
   ```
3. **Install pre-commit hooks**:
   ```bash
   pre-commit install
   ```

### Code Standards

- **Python**: Follow PEP 8, use Black formatter
- **Type Hints**: Required for all functions
- **Documentation**: Docstrings for all public methods
- **Testing**: Unit tests for new features

### Contribution Process

1. **Create feature branch**: `git checkout -b feature/amazing-feature`
2. **Make changes**: Implement your feature with tests
3. **Run tests**: `pytest tests/`
4. **Format code**: `black . && isort .`
5. **Commit changes**: Use conventional commit messages
6. **Push and create PR**: Include detailed description

### Areas for Contribution

- ğŸ§  **New AI Nodes**: Add specialized analysis capabilities
- ğŸŒ **Internationalization**: Support for more languages
- ğŸ“Š **Visualization**: Enhanced progress and result displays
- ğŸ”Œ **Integrations**: Connect with project management tools
- ğŸ§ª **Testing**: Improve test coverage and reliability
- ğŸ“š **Documentation**: Tutorials, examples, and guides

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **[LangChain](https://langchain.com/)** for the LangGraph framework
- **[FastAPI](https://fastapi.tiangolo.com/)** for the excellent web framework
- **[Streamlit](https://streamlit.io/)** for rapid UI development
- **[OpenAI](https://openai.com/)** for powerful language models

---

<div align="center">

**Made with â¤ï¸ by the AI Project Management Team**

[â­ Star this repo](https://github.com/yourusername/project-manager-assistant) â€¢
[ğŸ› Report Bug](https://github.com/yourusername/project-manager-assistant/issues) â€¢
[ğŸ’¡ Request Feature](https://github.com/yourusername/project-manager-assistant/issues)

</div>
