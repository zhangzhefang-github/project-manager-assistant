from redis import Redis
from rq import Queue
from rq.job import Job
from typing import Optional, Dict, Any
import time
import json

from app.core.config import settings

# Global Redis connection and RQ Queue
redis_conn = Redis(host=settings.REDIS_HOST, port=settings.REDIS_PORT)
task_queue = Queue(connection=redis_conn)

def update_job_progress(job_id: str, agent_state: Dict[str, Any]) -> bool:
    """
    æ›´æ–°ä»»åŠ¡çš„å®æ—¶è¿›åº¦ä¿¡æ¯åˆ°job.meta
    
    Args:
        job_id: ä»»åŠ¡ID
        agent_state: AgentStateå­—å…¸ï¼ŒåŒ…å«çœŸå®çš„æ‰§è¡ŒçŠ¶æ€
        
    Returns:
        æ›´æ–°æ˜¯å¦æˆåŠŸ
    """
    try:
        job = Job.fetch(job_id, connection=redis_conn)
        
        if job is None:
            return False
        
        # === è®¡ç®—çœŸå®çš„è¿›åº¦ç™¾åˆ†æ¯” ===
        completed_nodes = agent_state.get("completed_nodes", [])
        current_node = agent_state.get("current_node")
        
        # å®šä¹‰æ‰€æœ‰LangGraphèŠ‚ç‚¹ï¼ˆå¿…é¡»ä¸å®é™…æ‰§è¡Œé¡ºåºä¸€è‡´ï¼‰
        all_nodes = [
            "task_generation",     # ä»»åŠ¡ç”Ÿæˆ
            "analyze_dependencies", # ä¾èµ–åˆ†æ  
            "schedule_tasks",      # ä»»åŠ¡è°ƒåº¦
            "allocate_team",       # å›¢é˜Ÿåˆ†é…
            "assess_risk",         # é£é™©è¯„ä¼°
            "generate_insights"    # æ´å¯Ÿç”Ÿæˆ
        ]
        
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        if agent_state.get("overall_status") == "completed":
            progress = 100
        elif not completed_nodes and not current_node:
            progress = 0
        else:
            # åŸºäºå®Œæˆçš„èŠ‚ç‚¹æ•°é‡è®¡ç®—è¿›åº¦
            completed_count = len([node for node in completed_nodes if node in all_nodes])
            
            # å¦‚æœå½“å‰èŠ‚ç‚¹æ­£åœ¨æ‰§è¡Œä¸”ä¸åœ¨å·²å®Œæˆåˆ—è¡¨ä¸­ï¼Œç»™å®ƒ50%çš„æƒé‡
            if current_node and current_node in all_nodes and current_node not in completed_nodes:
                current_node_progress = 0.5  # æ­£åœ¨æ‰§è¡Œçš„èŠ‚ç‚¹ç®—50%å®Œæˆ
            else:
                current_node_progress = 0
                
            # è®¡ç®—æ€»è¿›åº¦ = (å·²å®ŒæˆèŠ‚ç‚¹æ•° + å½“å‰èŠ‚ç‚¹è¿›åº¦) / æ€»èŠ‚ç‚¹æ•° * 100
            total_progress = (completed_count + current_node_progress) / len(all_nodes)
            progress = min(int(total_progress * 100), 95)  # æœ€å¤š95%ï¼Œ100%ç•™ç»™çœŸæ­£å®Œæˆ
        
        # === ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºä¿¡æ¯ ===
        node_display_map = {
            "task_generation": "ğŸ§  æ™ºèƒ½ä»»åŠ¡æå–",
            "analyze_dependencies": "ğŸ”— ä¾èµ–å…³ç³»åˆ†æ", 
            "schedule_tasks": "ğŸ“… æ™ºèƒ½ä»»åŠ¡è°ƒåº¦",
            "allocate_team": "ğŸ‘¥ å›¢é˜Ÿæ™ºèƒ½åˆ†é…",
            "assess_risk": "âš ï¸ é£é™©è¯„ä¼°åˆ†æ",
            "generate_insights": "âœ¨ æ–¹æ¡ˆä¼˜åŒ–æ´å¯Ÿ"
        }
        
        current_node_display = node_display_map.get(current_node, current_node) if current_node else "å¤„ç†ä¸­"
        
        # æå–å…³é”®çš„çŠ¶æ€ä¿¡æ¯ï¼ˆé¿å…å­˜å‚¨è¿‡å¤šæ•°æ®ï¼‰
        progress_info = {
            "current_node": current_node,
            "current_node_display": current_node_display,
            "node_start_time": agent_state.get("node_start_time"),
            "total_start_time": agent_state.get("total_start_time"),
            "completed_nodes": completed_nodes,
            "node_progress": agent_state.get("node_progress", {}),
            "overall_status": agent_state.get("overall_status", "unknown"),
            "iteration_number": agent_state.get("iteration_number", 1),
            "last_updated": time.time(),
            
            # === æ–°å¢ï¼šçœŸå®è¿›åº¦ä¿¡æ¯ ===
            "progress": progress,  # çœŸå®è¿›åº¦ç™¾åˆ†æ¯”
            "total_nodes": len(all_nodes),  # æ€»èŠ‚ç‚¹æ•°
            "completed_count": len(completed_nodes),  # å·²å®ŒæˆèŠ‚ç‚¹æ•°
            "langgraph_flow": True,  # æ ‡è®°è¿™æ˜¯çœŸå®çš„LangGraphæµç¨‹
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            "total_elapsed_time": int(time.time() - agent_state.get("total_start_time", time.time())) if agent_state.get("total_start_time") else 0,
            
            # èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯
            "node_details": f"æ­£åœ¨æ‰§è¡Œ: {current_node_display}" if current_node else "å‡†å¤‡ä¸­...",
            
            # è¿­ä»£ä¿¡æ¯ï¼ˆå¦‚æœæœ‰å¤šè½®è¿­ä»£ï¼‰
            "iteration_info": f"ç¬¬ {agent_state.get('iteration_number', 1)} è½®è¿­ä»£" if agent_state.get("iteration_number", 1) > 1 else ""
        }
        
        # æ›´æ–°job.meta
        if not hasattr(job, 'meta') or job.meta is None:
            job.meta = {}
        
        job.meta["agent_state"] = progress_info
        job.save_meta()
        
        return True
        
    except Exception as e:
        print(f"Failed to update job progress: {e}")
        return False

def get_job_agent_state(job_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–ä»»åŠ¡çš„AgentStateä¿¡æ¯
    
    Args:
        job_id: ä»»åŠ¡ID
        
    Returns:
        AgentStateä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
    """
    try:
        job = Job.fetch(job_id, connection=redis_conn)
        
        if job is None or not hasattr(job, 'meta') or job.meta is None:
            return None
            
        return job.meta.get("agent_state")
        
    except Exception as e:
        print(f"Failed to get job agent state: {e}")
        return None

def get_job_detailed_status(job_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–ä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€ä¿¡æ¯
    
    Args:
        job_id: ä»»åŠ¡ID
        
    Returns:
        åŒ…å«è¯¦ç»†çŠ¶æ€ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚æœä»»åŠ¡ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    try:
        job = Job.fetch(job_id, connection=redis_conn)
        
        if job is None:
            return None
        
        # æ„å»ºè¯¦ç»†çŠ¶æ€ä¿¡æ¯
        status_info = {
            "job_id": job.id,
            "status": "queued" if job.is_queued else 
                     "started" if job.is_started else
                     "finished" if job.is_finished else
                     "failed" if job.is_failed else "unknown",
            "created_at": job.created_at.isoformat() if job.created_at else None,
            "started_at": job.started_at.isoformat() if job.started_at else None,
            "ended_at": job.ended_at.isoformat() if job.ended_at else None,
            "function_name": job.func_name if hasattr(job, 'func_name') else None,
            "description": job.description if hasattr(job, 'description') else None,
            "timeout": job.timeout if hasattr(job, 'timeout') else None,
        }
        
        # æ·»åŠ é˜Ÿåˆ—ä½ç½®ä¿¡æ¯
        if job.is_queued:
            status_info["position"] = job.get_position()
            
        # æ·»åŠ è¿›åº¦ä¿¡æ¯ï¼ˆåŸºäºæ—¶é—´ä¼°ç®—ï¼‰
        if job.is_started and job.started_at:
            elapsed_time = time.time() - job.started_at.timestamp()
            status_info["elapsed_time"] = elapsed_time
            
        # æ·»åŠ é”™è¯¯ä¿¡æ¯
        if job.is_failed:
            status_info["error"] = str(job.exc_info) if hasattr(job, 'exc_info') else "Unknown error"
            
        # æ·»åŠ ç»“æœä¿¡æ¯
        if job.is_finished and hasattr(job, 'result'):
            status_info["has_result"] = True
            # ä¸ç›´æ¥è¿”å›ç»“æœä»¥é¿å…æ•°æ®è¿‡å¤§ï¼Œé€šè¿‡ä¸“é—¨çš„ç«¯ç‚¹è·å–
            
        return status_info
        
    except Exception as e:
        return {
            "job_id": job_id,
            "status": "error",
            "error": f"Failed to fetch job status: {str(e)}"
        }

def get_queue_info() -> Dict[str, Any]:
    """
    è·å–é˜Ÿåˆ—çš„æ•´ä½“ä¿¡æ¯
    
    Returns:
        åŒ…å«é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    try:
        return {
            "queue_length": len(task_queue),
            "started_jobs": len(task_queue.started_job_registry),
            "finished_jobs": len(task_queue.finished_job_registry),
            "failed_jobs": len(task_queue.failed_job_registry),
            "deferred_jobs": len(task_queue.deferred_job_registry),
            "scheduled_jobs": len(task_queue.scheduled_job_registry),
        }
    except Exception:
        return {"error": "Failed to get queue info"} 